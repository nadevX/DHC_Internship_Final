{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333cb79c-4c24-4262-b8ab-0540cbe80d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deforestation detection system ready!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Planet/planet\\train-jpg: 100%|██████████| 1000/1000 [00:01<00:00, 594.06it/s]\n",
      "C:\\Users\\Moon-Study\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - accuracy: 0.9807 - loss: 0.0356 - val_accuracy: 1.0000 - val_loss: 4.9992e-22\n",
      "Epoch 2/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 2.5745e-17 - val_accuracy: 1.0000 - val_loss: 4.9799e-22\n",
      "Epoch 3/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 8.9125e-20 - val_accuracy: 1.0000 - val_loss: 4.9799e-22\n",
      "Epoch 4/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 2.9388e-18 - val_accuracy: 1.0000 - val_loss: 4.9799e-22\n",
      "Epoch 5/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 1.1312e-18 - val_accuracy: 1.0000 - val_loss: 4.9799e-22\n",
      "Epoch 6/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 3.7692e-20 - val_accuracy: 1.0000 - val_loss: 4.9799e-22\n",
      "Epoch 7/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 5.2793e-18 - val_accuracy: 1.0000 - val_loss: 4.9799e-22\n",
      "Epoch 8/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 2.3536e-19 - val_accuracy: 1.0000 - val_loss: 4.9799e-22\n",
      "Epoch 9/10\n",
      "\u001b[1m 17/100\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 112ms/step - accuracy: 1.0000 - loss: 4.4486e-23"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Define dataset directories\n",
    "DATASET_DIR = \"Planet/planet\"\n",
    "TRAIN_DIR = os.path.join(DATASET_DIR, \"train-jpg\")\n",
    "TEST_DIR = os.path.join(DATASET_DIR, \"test-jpg\")\n",
    "\n",
    "# Optimized parameters for weak CPU\n",
    "IMG_SIZE = (128, 128)  # Adjusted for efficiency\n",
    "BATCH_SIZE = 8         # Reduced batch size to lower memory usage\n",
    "EPOCHS = 10            # Adjusted epochs for balance between accuracy and speed\n",
    "\n",
    "# Define a CNN model\n",
    "def build_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3,3), activation='relu', input_shape=(128, 128, 3)),\n",
    "        MaxPooling2D(2,2),\n",
    "        Conv2D(64, (3,3), activation='relu'),\n",
    "        MaxPooling2D(2,2),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.4),\n",
    "        Dense(1, activation='sigmoid')  # Binary classification\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Preprocess dataset with memory optimization\n",
    "def preprocess_dataset(input_dir, limit=None):\n",
    "    images = []\n",
    "    labels = []\n",
    "    image_files = [f for f in os.listdir(input_dir) if f.endswith(\".jpg\")]\n",
    "    if limit:\n",
    "        image_files = image_files[:limit]  # Limit dataset to reduce memory usage\n",
    "    for img_file in tqdm(image_files, desc=f\"Processing {input_dir}\"):\n",
    "        img_path = os.path.join(input_dir, img_file)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "        img = cv2.resize(img, IMG_SIZE)\n",
    "        img = img / 255.0\n",
    "        images.append(img)\n",
    "        labels.append(0)  # Placeholder label\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Train the model with memory efficiency\n",
    "def train_model():\n",
    "    train_images, train_labels = preprocess_dataset(TRAIN_DIR, limit=1000)  # Limit training data\n",
    "    model = build_model()\n",
    "    model.fit(train_images, train_labels, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.2)\n",
    "    model.save(os.path.join(DATASET_DIR, \"deforestation_model.h5\"))\n",
    "    print(\"Model training complete!\")\n",
    "\n",
    "# Test model on a randomly selected test image\n",
    "def test_model():\n",
    "    model_path = os.path.join(DATASET_DIR, \"deforestation_model.h5\")\n",
    "    if not os.path.exists(model_path):\n",
    "        print(\"Error: Model file not found! Training the model first...\")\n",
    "        train_model()\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "    image_files = [f for f in os.listdir(TEST_DIR) if f.endswith(\".jpg\")]\n",
    "    if not image_files:\n",
    "        print(\"No test images found!\")\n",
    "        return\n",
    "    \n",
    "    img_file = random.choice(image_files)  # Select a random test image\n",
    "    img_path = os.path.join(TEST_DIR, img_file)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(\"Error: Could not read image!\")\n",
    "        return\n",
    "    \n",
    "    img_resized = cv2.resize(img, IMG_SIZE) / 255.0\n",
    "    img_resized = np.expand_dims(img_resized, axis=0)\n",
    "    \n",
    "    prediction = model.predict(img_resized)[0][0]\n",
    "    \n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Deforestation Probability: {prediction:.2f}\\n({img_file})\")\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    print(\"Deforestation detection system ready!\")\n",
    "    train_model()\n",
    "    test_model()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b155de78-a78a-4de8-b80c-04dacc66a8da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
